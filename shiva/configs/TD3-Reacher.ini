; Test config for DQN
; NOTE: options within sections cannot have the same names

[MetaLearner]
type='SingleAgentMetaLearner'
start_mode="production"
optimize_env_hp=False
optimize_learner_hp=False
evolution=False

[Learner]
type                        = 'SingleAgentTD3Learner'
using_buffer                = True
episodes                    = 20000
load_agents                 = False
; load_agents = "runs/TD3Algorithm-Reacher-12-14-04:10/"
; load_agents = "runs/TD3Algorithm-Reacher-12-14-10:53/"
; load_agents = "runs/TD3Algorithm-Reacher-12-14-11:14_1/"
; load_agents = "runs/TD3Algorithm-Reacher-12-14-13:13/"
; load_agents = "runs/TD3Algorithm-Reacher-12-14-14:12/"
; load_agents = "runs/TD3Algorithm-Reacher-12-14-14:23/"
;load_agents = "runs/TD3Algorithm-Reacher-12-14-22:57/"

[Algorithm]
type                        = "TD3Algorithm"
manual_seed                 = 69
exploration_steps           = 0
update_iterations           = 3
loss_function               = 'MSELoss'
gamma                       = 0.9999
; c is the number of steps needed to update target nets
c                           = 10000
actor_soft_update           = 0.01
critic_soft_update          = 0.01
actor_grad_clip_norm        = None
critic_grad_clip_norm       = None
noise_scale                 = 0.65
noise_mu                    = 0
noise_theta                 = 0.15
noise_sigma                 = 0.25
; action_noise_std            = 0.1
; action_noise_clipping_range = 0.3

[Environment]
type                    = 'UnityWrapperEnvironment'
exec                    = 'shiva/envs/unitybuilds/Reacher-11_Mac/Reacher.app'
env_name                = 'Reacher'
train_mode              = True
render                  = True
reset_params            = {}

[Buffer]
type            = 'SimpleBuffer'
capacity        = 100000
batch_size      = 256

[Agent]
manual_seed         = 69
optimizer_function  = 'Adam'
eps                 = 1e-4
actor_lr            = 0.001
critic_lr           = 0.001
critic_2_lr         = 0.001

[Network]
actor = {'layers': [512, 256], 'activation_function': ['ReLU', 'ReLU'], 'output_function': None, 'last_layer': True}
critic = {'layers': [512], 'activation_function': ['ReLU'], 'output_function': None, 'last_layer': True}
critic_2 = {'layers': [512], 'activation_function': ['ReLU'], 'output_function': None, 'last_layer': True}

[Admin]
save                = True
traceback           = True
directory           = {'runs': '/runs'}

[ImageProcessing]


[VideoProcessing]
