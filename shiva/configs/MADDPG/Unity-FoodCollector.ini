[MetaLearner]
type = 'MPIPBTMetaLearner'
pbt = False
num_mevals = 1
learners_map = {'configs/MADDPG/Agent-FoodCollector.ini': ['FoodCollector?team=0']}
num_learners_maps = 1
num_menvs_per_learner_map = 1

[Evaluation]
device = "cpu"
expert_population = 0.1
num_evals = 3
num_envs = 1
render = False
eval_episodes = 10

[Environment]
device = "gpu"
type = 'MultiAgentUnityWrapperEnv1'
;exec = 'shiva/envs/unitybuilds/1/FoodCollector/FoodCollector.app'
exec = 'shiva/envs/unitybuilds/1/FoodCollector/FoodCollector.x86_64'
env_name = 'FoodCollector'
num_envs = 3
episode_max_length = 1000
episodic_load_rate = 1
expert_reward_range = {'FoodCollector?team=0': [4, 100]}
render = False
port = 5010
share_viewer = True
normalize = False
;reward_factor = 0.001
;min_reward = -1000
;max_reward = 2
;unity_configs = { 'time_scale': 20 }
unity_configs = {}
unity_props = {}
;timeout_wait = 120

[Admin]
iohandler_address   = 'localhost:50001'
print_debug         = True
save                = True
traceback           = True
directory           = {'runs': '/runs/Unity-FoodCollector/'}
profiler            = True
time_sleep = {'MetaLearner':    0,
             'MultiEnv':        0.01,
             'EvalWrapper':     1,
             'Evaluation':      0.1}
; verbose levels for logs and terminal output
;   0 deactivated
;   1 debug
;   2 info
;   3 details
log_verbosity = {
    'Admin':        0,
    'IOHandler':    1,
    'MetaLearner':  1,
    'Learner':      1,
    'Agent':        0,
    'Algorithm':    0,
    'MultiEnv':     1,
    'Env':          1,
    'EvalWrapper':  1,
    'Evaluation':   1,
    'EvalEnv':      0
    }
