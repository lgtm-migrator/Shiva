[MetaLearner]
type = 'MPIPBTMetaLearner'
pbt = False
num_mevals = 1
learners_map = {'configs/MADDPG/Agent-Figure8Hide.ini': ['Red_0?team=1', 'Red_1?team=1']}
;learners_map = {'configs/MADDPG/Agent-Figure8Hide.ini': ['svgraph:svGraph-v0']}
num_learners_maps = 1
num_menvs_per_learner_map = 1

[Evaluation]
device = "cpu"
expert_population = 0.1
num_evals = 3
num_envs = 1
render = True
eval_episodes = 10

[Environment]
device = "cuda:0"
type = 'MultiAgentUnityWrapperEnv15'
exec = 'shiva/envs/unitybuilds/Release15/2021-03-24_Figure8Hide2_v1.01_ObsSize20_ActSize5,3/HA3T_Figure8Hide.x86_64'
env_name = 'BuildingSkirmish'
num_envs = 1
episode_max_length = 35
episodic_load_rate = 1
;expert_reward_range = {'Red_0?team=1': [190, 1000], 'Red_1?team=1': [190, 1000], 'Red_2?team=1': [190, 1000], 'Red_3?team=1': [190, 1000]}
expert_reward_range = {'Red_0?team=1': [190, 1000], 'Red_1?team=1': [190, 1000]}
;expert_reward_range = {'Red_0?team=1': [190, 1000]}
;expert_reward_range = {'Red_0?team=1': [300, 1000]}
;roles_remap = {'svgraph:svGraph-v0': 'Red_0?team=1'}
skip_episodes = 0
render = True
port = 5000
share_viewer = True
normalize = False
unity_configs = {}
;unity_props = { 'num_red_agents': 2,
;                'red_initwaypoint_0': 1317, 'red_initwaypoint_1': 1400, 'red_initwaypoint_2': 1317, 'red_initwaypoint_3': 1401,
;                'num_blue_teams': 1,
;                'unitydebug': 1, 'rldebug': 1, 'decision_interval': 5,
;              }
;unity_props = {}
unity_props = { 'num_red_agents': 2,
                'red_maxhealth': 80,
                'bonus_spot': 1303,
                'bonus_spot1': 1203,
		'NiR_Step_Bonus': 0,
		'NiS_Step_Bonus': 0,
		'oneHotOverride': 1,
                'red_initwaypoint_0': 1303, 'red_initwaypoint_1': 1100,
                'red_initwaypoint_2': 1204, 'red_initwaypoint_3': 1204,
                'initwaypoint_randompoolsize': 1,'red_initwaypoint_0r1': 1101,'red_initwaypoint_0r2': 1102,'red_initwaypoint_0r3': 1203,'red_initwaypoint_0r4': 1204,'red_initwaypoint_0r5': 1101,'red_initwaypoint_0r6': 1304,'red_initwaypoint_0r7': 1403,'red_initwaypoint_0r8': 1404,'red_initwaypoint_0r9': 1405,'red_initwaypoint_1r1': 1101,'red_initwaypoint_1r2': 1102,'red_initwaypoint_1r3': 1203,'red_initwaypoint_1r4': 1204,'red_initwaypoint_1r5': 1303,'red_initwaypoint_1r6': 1304,'red_initwaypoint_1r7': 1403,'red_initwaypoint_1r8': 1404,'red_initwaypoint_1r9': 1405,
                'num_blue_teams': 1,
                'blue_maxhealth': 80,
                'blue_team_path_0': 0,
                'max_step': 40,
                'mask_actions': 1,
		'use_terrain_observations': 0,
		'range_based_step': 0,
                'time_penalty': 0, 'time_penalty_linear': 0, 'time_penalty_quadratic': 0,
		'team_lose_reward': 0, 'team_win_base_reward': 0, 'team_win_health_reward_multiplier': 0,
                'full_health_bonus': 0,
		'team_win_isalive_reward': 0, 'team_win_numaliveteammates_reward_multiplier': 0,
                'unitydebug': 0, 'rldebug': 0,
                'is_survival_win_condition': 1,
                'damage_reward_multiplier': 0,
                'timescale': 99, 'timeout_seconds': 30,
                'red_numammoclips': 9, 'blue_numammoclips': 9,
                'size_blue_team': 1,'userangeobs': 1,'pov_angle':120,'numAttacksPerStep':1,'alwaysHit':1,'individualorglobalobs':1,'redShootsAtBlue_Step_Bonus':3,'iR_or_iS_Step_Bonus':-2,
                'RsB_NiR_Step_Bonus':0,'multipleOccupancy_Step_Bonus':-1,'usesightobs':1,'usefacingdirection':1,'userangeobs':1,'usehalfpathindicatorobs':0,'individualorglobalobs':1,'useRotationAction':1,
                'hitcount_reward_table_size':6,'hitcount_reward_table_0':100,'hitcount_reward_table_1':90,'hitcount_reward_table_2':70,'hitcount_reward_table_3':40,'hitcount_reward_table_4':10,'endOfEpisodeDelay':6,'attack_at_end_of_step':1
              }
timeout_wait = 150

[Admin]
iohandler_address   = 'localhost:50001'
print_debug         = True
save                = True
traceback           = True
directory           = {'runs': '/runs/Unity-Figure8Hide/'}
profiler            = True
time_sleep = {'MetaLearner':    0,
             'MultiEnv':        0.01,
             'EvalWrapper':     1,
             'Evaluation':      0.1}
; verbose levels for logs and terminal output
;   0 deactivated
;   1 debug
;   2 info
;   3 details
log_verbosity = {
    'Admin':        1,
    'IOHandler':    0,
    'MetaLearner':  1,
    'Learner':      3,
    'Agent':        0,
    'Algorithm':    0,
    'MultiEnv':     1,
    'Env':          3,
    'EvalWrapper':  0,
    'Evaluation':   0,
    'EvalEnv':      0
    }
