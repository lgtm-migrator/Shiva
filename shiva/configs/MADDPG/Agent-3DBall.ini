[Learner]
episodes = 100000
evaluate = False
load_agents = False
save_checkpoint_episodes = 1000
episodes_to_update = 1
n_traj_pulls = 5

evolve = False
initial_evolution_episodes = 1000
evolution_episodes = 500
p_value = 0.05
perturb_factor = [0.8, 1.2]

[Algorithm]
type = "MADDPGAlgorithm"
method = "permutations"
update_iterations = 1
loss_function = 'MSELoss'
gamma = 0.999
tau = 0.01

[Buffer]
;type = 'MultiTensorBuffer.MultiAgentTensorBuffer'
type = 'MultiTensorBuffer.PrioritizedMultiAgentTensorBuffer'
capacity = 100000
batch_size = 128

prioritized = False
omicron = 0.0001
alpha = 0.6

beta_start = 0.4
beta_end = 1
beta_steps = 1_000_000
beta_decay_degree = 1

stochastic_samples = 3000
epsilon_start = 0.95
epsilon_end = 0.1
epsilon_decay_degree = 2

[Agent]
hp_random = False
lr_factors = [1000, 10000]
lr_uniform = [1, 10]
epsilon_range = [0, 0.5]
ou_range = [0, 0.5]

optimizer_function = 'Adam'
actor_learning_rate = 0.0001
critic_learning_rate = 0.0001
lr_decay = {'factor': 0.5, 'average_episodes': 50, 'wait_episodes_to_decay': 15}
exploration_steps = 5000

actions_range = [-1, 1]
epsilon_start = 0.5
epsilon_end = 0.01
epsilon_episodes = 1000
epsilon_decay_degree = 1

noise_start = 0.5
noise_end = 0.1
noise_episodes = 5000
noise_decay_degree = 1

[Network]
actor = {'layers': [128, 128], 'activation_function': ['ReLU', 'ReLU'], 'output_function': None, 'last_layer': True}
critic = {'layers': [128, 128], 'activation_function': ['ReLU', 'ReLU'], 'output_function': None, 'last_layer': True}
