[MetaLearner]
type = 'MPIPBTMetaLearner'
pbt = False
num_mevals = 1
learners_map = {'configs/DQN/Agent-Cartpole.ini': ['Agent_0']}
; for population of learners:
num_learners_maps = 2
; for many training multienvs per individual learner:
num_menvs_per_learners_map = 1

[Evaluation]
eval_events = ['Average_Reward']
;sort_ascending = [False, True, True, False, True]
;eval_weights = [0.05, 0.1, 0.1, 0.2, 0.2, 0.35 ]
num_evals = 2
num_envs = 1
;num_agents = 3
;agents_per_env = 1
eval_episodes = 10
eval_path = 'pbt_agents/'

[Environment]
type = 'GymEnvironment'
env_name = 'CartPole-v0'
action_space = 'discrete'
episode_max_length = 200
num_envs = 2
render = False
port = 5010
normalize = True
reward_factor = 0.01
min_reward = 0
max_reward = 1

[Admin]
print_debug         = True
save                = True
traceback           = True
directory           = {'runs': '/runs/dqn-cartpole/'}
