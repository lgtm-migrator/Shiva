[MetaLearner]
type = 'MPIPBTMetaLearner'
pbt = False
num_mevals = 1
learners_map = {'configs/PBT/MADDPG-Agent.ini': ['Agent_Purple', 'Agent_Blue']}
; for population of learners:
num_learners_maps = 2
; for many training multienvs per individual learner:
num_menvs_per_learners_map = 1

[Evaluation]
device = "cpu"
;eval_events = ['Average_Reward']
;sort_ascending = [False, True, True, False, True]
;eval_weights = [0.05, 0.1, 0.1, 0.2, 0.2, 0.35 ]
expert_population = 0.2
num_evals = 2
num_envs = 1
;num_agents = 3
;agents_per_env = 1
eval_episodes = 25
eval_path = 'pbt_agents/'

[Environment]
device = "cpu"
type = 'MultiAgentUnityWrapperEnv'
num_envs = 1
episode_max_length = 31
exec = 'shiva/envs/unitybuilds/12/BasicMultiColor-12_Mac/BasicMulti.app'
port = 5010
render = False
unity_configs = { 'time_scale': 30 }
unity_props = { }
timeout_wait = 60
normalize = False
;reward_factor = 0.1
;min_reward = 0
;max_reward = 1

[Admin]
print_debug         = True
save                = True
traceback           = True
directory           = {'runs': '/runs/pbt-maddpg-basicmulti/'}
time_sleep = {'MetaLearner':    0,
             'MultiEnv':        0.1,
             'EvalWrapper':     2,
             'Evaluation':      0.2}
; verbose levels for logs and terminal output
;   0 deactivated
;   1 debug
;   2 info
;   3 details
log_verbosity = {
    'Admin':        0,
    'IOHandler':    0,
    'MetaLearner':  0,
    'Learner':      2,
    'Algorithm':    0,
    'MultiEnv':     1,
    'Env':          2,
    'EvalWrapper':  1,
    'Evaluation':   1,
    'EvalEnv':      0
    }