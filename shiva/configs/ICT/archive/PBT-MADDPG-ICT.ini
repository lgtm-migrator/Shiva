
[MetaLearner]
type='MPIPBTMetaLearner'
pbt = True
num_mevals = 1
; Decentralized Learners
learners_map = {'configs/ICT/PBT-MADDPG-ICT-Agent_1.ini': ['Agent_1'],
                'configs/ICT/PBT-MADDPG-ICT-Agent_3.ini': ['Agent_3']}
num_learners_maps = 3
num_menvs_per_learner_map = 1

[Evaluation]
device = "cpu"
expert_population = 0.2
num_evals = 3
num_envs = 1
eval_episodes = 1
eval_path = "pbt_agents/"

[Environment]
device = "cpu"
type='MultiAgentUnityWrapperEnv'
num_envs = 2
episode_max_length = 20
exec='shiva/envs/unitybuilds/HA3T_r2b3_v0.04_2020-03-11_Discrete/HA3T_r2b3_v0.04_2020-03-11_Discrete.x86_64'
train_mode = True
render = False
port = 5700
unity_configs = { 'time_scale': 40 }
unity_props = { }

[Admin]
print_debug         = True
save                = True
traceback           = True
directory           = {'runs': '/runs/'}
time_sleep = {'MetaLearner':    0,
             'MultiEnv':        0.1,
             'EvalWrapper':     1,
             'Evaluation':      0.1}
; verbose levels for logs and terminal output
;   0 deactivated
;   1 debug
;   2 info
;   3 details
log_verbosity = {
    'Admin':        0,
    'IOHandler':    0,
    'MetaLearner':  1,
    'Learner':      1,
    'Algorithm':    0,
    'MultiEnv':     1,
    'Env':          0,
    'EvalWrapper':  1,
    'Evaluation':   1,
    'EvalEnv':      0
    }
