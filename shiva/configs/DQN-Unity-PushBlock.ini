; Test config for DQN
; NOTE: options within sections cannot have the same names

[MetaLearner]
type='SingleAgentMetaLearner'
start_mode="production"
optimize_env_hp=False
optimize_learner_hp=False
evolution=False

[Learner]
type = 'SingleAgentDQNLearner'
using_buffer = True
episodes = 1000000
load_agents = False
; load_agents = "runs/ML-PushBlock-DQNAlgorithm-12-12-20:30/L-0/"
save_checkpoint_episodes = 10

[Algorithm]
type = 'DQNAlgorithm'
manual_seed = 5
exploration_steps = 32000
replay_buffer = True
loss_function = 'MSELoss'
regularizer = 0
recurrence = False
gamma = 0.9
epsilon_start = 0.5
epsilon_end = 0.02
epsilon_decay = 0.0005
c = 5

[Environment]
type='UnityWrapperEnvironment'
exec='shiva/envs/unitybuilds/PushBlock-11_Mac/PushBlock.app'
env_name='PushBlock'
train_mode = True
reset_params = {}
render = True

[Buffer]
type = 'SimpleBuffer'
capacity = 100000
batch_size = 1028
num_agents = 1

[Agent]
num_agents = 1
optimizer_function = 'Adam'
learning_rate = 0.001

[Network]
network = {'layers': [512, 256, 128, 64], 'activation_function': ["ReLU", "ReLU", "ReLU", "ReLU"], 'output_function': None, 'last_layer': True}

[Admin]
save                = True
traceback           = True
directory           = {'runs': '/runs'}

[ImageProcessing]


[VideoProcessing]


