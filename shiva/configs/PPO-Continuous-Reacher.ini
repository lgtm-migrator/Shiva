[MetaLearner]
type='SingleAgentMetaLearner'
start_mode="production"
optimize_env_hp=False
optimize_learner_hp=False
evolution=False

[Learner]
type='SingleAgentPPOLearner'
using_buffer=True
episodes=50
load_agents=False
process_count = 5
; load_agents = 'runs/ML-MountainCarContinuous-v0-10-31-20:00'
save_checkpoint_episodes = 10

[Algorithm]
algorithm='PPO'
type="ContinuousPPOAlgorithm"
manual_seed = 3
update_episodes= 3
update_epochs = 10
replay_buffer=True
loss_function='MSELoss'
regularizer=0
recurrence=0
gamma=0.99
lambda = 0.95
beta=0.0001
epsilon_clip = 0.1


; [Environment]
; type='GymEnvironment'
; env_name='CartPole-v0'
; action_space='discrete'
; observation_space="continuous"
; render=False
; num_agents=1
; normalize=True
; b=1
; a=-1
; min=-1
; max=100

[Environment]
type='UnityWrapperEnvironment'
exec='shiva/envs/unitybuilds/Reacher-11_Mac/Reacher.app'
env_name='Reacher'
; discrete_action_size = 2
; exec='shiva/envs/unitybuilds/PushBlock/PushBlock.x86_64'
; env_name='PushBlock'
; action_space_discrete = 7
train_mode = True
render = True
reset_params = {}


[Buffer]
type='SimpleBuffer'
capacity=5012
batch_size = 128
num_agents=1

[Agent]
action_space = 'Continuous'
num_agents=1
manual_seed = 1
optimizer_function='Adam'
learning_rate=0.0001
eps=1e-4

[Network]
actor = {'layers': [256, 128], 'activation_function': ['ReLU', 'ReLU'], 'output_function': 'Softmax', 'last_layer': True}
mu = {'layers': [256, 128], 'activation_function': ['ReLU', 'Tanh'], 'output_function': None, 'last_layer': True}
var = {'layers': [256, 128], 'activation_function': ['ReLU', 'Softplus'], 'output_function': None, 'last_layer': True}
critic = {'layers': [256, 128], 'activation_function': ['ReLU', 'ReLU'], 'output_function': None, 'last_layer': True}
policy_base_output = 256

[Admin]
save                = True
traceback           = True
directory           = {'runs': '/runs'}

[ImageProcessing]


[VideoProcessing]
